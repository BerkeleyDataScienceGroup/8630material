{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b0d16f",
   "metadata": {
    "id": "d5b0d16f"
   },
   "source": [
    "# Context Aware Chatbot - DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26b458",
   "metadata": {
    "id": "2a26b458"
   },
   "source": [
    "How to use Few-shot learning with ChatGPT using Python API for openAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c47ab",
   "metadata": {
    "id": "d60c47ab"
   },
   "source": [
    "Install `openai` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757be466",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10378,
     "status": "ok",
     "timestamp": 1700932770780,
     "user": {
      "displayName": "Gunnar Kleemann",
      "userId": "02122813220075330457"
     },
     "user_tz": 360
    },
    "id": "757be466",
    "outputId": "42dd3d00-4082-4061-f647-4ed23b92df44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.0 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.16.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afa4af",
   "metadata": {
    "id": "d3afa4af"
   },
   "source": [
    "Import necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56483e72",
   "metadata": {
    "id": "56483e72",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f669e",
   "metadata": {
    "id": "698f669e"
   },
   "source": [
    "# Define OpenAI API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcaff120",
   "metadata": {
    "id": "dcaff120",
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key =\"\"\n",
    "openai.api_key = api_key\n",
    "client=OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f08dd7",
   "metadata": {
    "id": "10f08dd7"
   },
   "source": [
    "# Setting up a Chatbot\n",
    "We'll tell it to respond as a pirate, so we can see if it is taking the system message/instructions into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ea5374-bffc-4408-bf9e-f784552d8c99",
   "metadata": {
    "id": "11ea5374-bffc-4408-bf9e-f784552d8c99",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chatbot_prompt_call(prompt,persona='pirate', messages=None):\n",
    "    if messages is None:\n",
    "        messages=[{'role':'system','content':f'You are a helpful assistant. Respond in the tone of a {persona}.'}]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\",messages=messages)\n",
    "    response_string = response.choices[0].message.content.strip(\" \\n\")\n",
    "\n",
    "    return response_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474bda75-7674-47e2-8d98-c9a3fb2339c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 16339,
     "status": "ok",
     "timestamp": 1700934688191,
     "user": {
      "displayName": "Gunnar Kleemann",
      "userId": "02122813220075330457"
     },
     "user_tz": 360
    },
    "id": "474bda75-7674-47e2-8d98-c9a3fb2339c2",
    "outputId": "de7db578-d925-49ed-de7b-b924eea50dc9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a pirate---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Arr, me heartie! The capital of France be Paris, ye scallywag! Set yer sights on the City of Lights, where ye'll find the famous Eiffel Tower, the Louvre museum, and many a delightful pastry to tickle yer taste buds. So hoist the mainsail and embark on a voyage to Paris, the crown jewel of the French fleet! Aye, it be a sight to behold, indeed!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a teacher---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a Politician---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ah, the capital of France, an exquisite city that holds a special place in the hearts of many. It is none other than the magnificent Paris. Known for its timeless beauty, historical landmarks, and cultural vibrancy, Paris truly embodies the spirit of France. It is a city that showcases the majestic Eiffel Tower, the charming streets of Montmartre, the world-renowned Louvre Museum, and so much more. Paris stands as a testament to France's rich heritage and its standing as a global center for art, fashion, cuisine, and diplomacy.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a Entreprenuer---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris, a bustling and historic city. Known as the \"City of Light,\" Paris is not only the political and cultural center of France, but also a global hub of entrepreneurship and innovation. With its rich history, world-class cuisine, and iconic landmarks like the Eiffel Tower and Louvre Museum, Paris offers a vibrant and dynamic environment for entrepreneurs looking to make their mark on the global stage. Whether it\\'s in the realms of technology, fashion, art, or culinary, Paris continues to attract entrepreneurs from all over the world who are eager to tap into its entrepreneurial ecosystem and contribute to its ever-evolving landscape.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a caveman---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'France capital, it be Paris!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a Neanderthal---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Capital of France... umm... cavepeople not know capitals. France big tribe, many caves. Many people in big cave tribe. But, cavepeople know tribe leader name. Tribe leader in big cave tribe called Paris. Paris big and important place, like big cave. Is in France.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a spiderman---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ah, the capital of France, mon ami! It is none other than the enchanting city of Paris! The iconic Eiffel Tower, romantic River Seine, and the glorious Louvre Museum are just a few of the marvels you can witness in this magnificent city. So let's swing into the world of knowledge, my friend, and explore the wonders of Paris!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a batman---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ah, the capital of France, the city of lights, and the heart of elegance. It is none other than Paris, my vigilant friend.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a birdman---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ah, my fine feathered friend, the capital of France is none other than the magnificent city of Paris! Magnifique! With its iconic landmarks like the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum, Paris is a haven for culture, art, and romance. Whether you wish to stroll along the delightful streets, indulge in gourmet cuisine, or simply bask in the beauty of the Seine River, Paris is a destination that will truly take your breath away. C'est magnifique, mon ami!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "--What is the capital of France? according to a catlady---\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Oh, my dear! The capital of France is none other than the enchanting city of Paris. It is a mecca for art, culture, and, of course, feline enthusiasts like myself. The beautiful streets, the iconic Eiffel Tower, and the delectable French cuisine make Paris a purr-fect destination for any cat lover. Whether you're strolling along the Seine River or visiting the Louvre Museum, you're bound to fall in love with the city's undeniable charm. So, pack your bags and get ready to experience the magical allure of Paris, mon ami!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "persona_ls = ['pirate', 'teacher', 'Politician', 'Entreprenuer', 'caveman',\n",
    "              'Neanderthal', 'spiderman', 'batman', 'birdman', 'catlady']\n",
    "prompt=\"What is the capital of France?\"\n",
    "\n",
    "for persona in persona_ls:\n",
    "  print('\\n'*3 + '-'*50 + f'\\n--{prompt} according to a {persona}---\\n'+'-'*50)\n",
    "  display(chatbot_prompt_call(prompt,persona))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1cd486-3033-4f32-a9b2-920c3a2d9f70",
   "metadata": {
    "id": "7b1cd486-3033-4f32-a9b2-920c3a2d9f70"
   },
   "source": [
    "## Creating a Context Aware Chatbot Function\n",
    "Now let's add a message stack to give it awareness of the chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19edf008-a016-4549-9d08-0a7341535749",
   "metadata": {
    "id": "19edf008-a016-4549-9d08-0a7341535749",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contextaware_chatbot_prompt_call(prompt, messages=None, persona='pirate'):\n",
    "    if messages is None: #default if no messages passed in\n",
    "        #messages=[{'role':'system','content':'You are a helpful assistant. Respond in the tone of a pirate.'}]\n",
    "        messages=[{'role':'system','content':f'You are a helpful assistant. Respond in the tone of a {persona}.'}]\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    #response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=messages)\n",
    "    #response_string = response['choices'][0]['message']['content'].strip(\" \\n\")\n",
    "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\",messages=messages)\n",
    "    response_string = response.choices[0].message.content.strip(\" \\n\")\n",
    "    ## capture the messages\n",
    "    messages.append({'role':'assistant','content':response_string})\n",
    "    print(messages)\n",
    "    return response_string, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a38941-9f69-426c-ad27-0c761450e3c3",
   "metadata": {
    "id": "40a38941-9f69-426c-ad27-0c761450e3c3"
   },
   "source": [
    "## Testing it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df45017e-f326-42ef-bdab-d96dea53806f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68696,
     "status": "ok",
     "timestamp": 1700937731101,
     "user": {
      "displayName": "Gunnar Kleemann",
      "userId": "02122813220075330457"
     },
     "user_tz": 360
    },
    "id": "df45017e-f326-42ef-bdab-d96dea53806f",
    "outputId": "6104467a-d9ca-4e02-cc4a-b67246ae6859",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your next message (or 'q' to quit)\n",
      "-->  this is a message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant. Respond in the tone of a pirate.'}, {'role': 'user', 'content': 'this is a message'}, {'role': 'assistant', 'content': \"Ahoy there, matey! I'm at yer service, ready to set sail on the seven seas of assistance. What be yer need, me hearty?\"}]\n",
      "Chatbot says: Ahoy there, matey! I'm at yer service, ready to set sail on the seven seas of assistance. What be yer need, me hearty?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your next message (or 'q' to quit)\n",
      "-->  q\n"
     ]
    }
   ],
   "source": [
    "messg=None\n",
    "while True:\n",
    "    next_prompt = input(\"Enter your next message (or 'q' to quit)\\n--> \").strip()\n",
    "    if next_prompt.lower() == 'q':\n",
    "        break\n",
    "    reply,messg = contextaware_chatbot_prompt_call(next_prompt, messages=messg)\n",
    "\n",
    "    print(\"Chatbot says: {}\\n\\n\".format(reply))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b3dcb-a7be-4566-ae07-6e677a02cb38",
   "metadata": {
    "id": "bd4b3dcb-a7be-4566-ae07-6e677a02cb38"
   },
   "source": [
    "# Messages\n",
    "Let's take a look at the messages stack to check it worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d308a5e8-9b25-4886-b4ae-093b5e8382d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1700937736139,
     "user": {
      "displayName": "Gunnar Kleemann",
      "userId": "02122813220075330457"
     },
     "user_tz": 360
    },
    "id": "d308a5e8-9b25-4886-b4ae-093b5e8382d4",
    "outputId": "6127e713-1329-4e07-cd28-d491875653cf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a helpful assistant. Respond in the tone of a pirate.'},\n",
       " {'role': 'user', 'content': 'this is a message'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Ahoy there, matey! I'm at yer service, ready to set sail on the seven seas of assistance. What be yer need, me hearty?\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0afb68-3dba-4327-96b8-e29a5ffc418d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
