{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270c8b93-80d4-4e72-9c6b-9c94e324e378",
   "metadata": {},
   "source": [
    "# Exercise: Free Dolly ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74647ce-ad7f-45e7-b85e-40620a3bad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"accelerate>=0.16.0,<1\" \"transformers[torch]>=4.28.1,<5\" \"torch>=1.13.1,<2\" --quiet\n",
    "!pip install langchain>=0.0.139 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c625c7-7fc7-448e-b74a-661090a9f81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain==0.0.309 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a7fdf-f61c-453d-a4c0-d0a6d4a2b957",
   "metadata": {},
   "source": [
    "## First, load up the Free Dolly LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ae07f-534c-4a0b-a5db-0096c86a742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fdd3437fa74affbdc3e48c687f099f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938474a4c07547d6a7da0654650da5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)instruct_pipeline.py:   0%|          | 0.00/9.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/databricks/dolly-v2-3b:\n",
      "- instruct_pipeline.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f9cedccf194ea387198158d4d8f3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#student code goes here\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "dolly = pipeline(model=\"databricks/dolly-v2-3b\",\n",
    "                         torch_dtype=torch.bfloat16,\n",
    "                         trust_remote_code=True,\n",
    "                         device_map=\"auto\",\n",
    "                         return_full_text=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfff69-b00b-4e07-b708-89bab5cfa96d",
   "metadata": {},
   "source": [
    "## Load any libraries you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353a5d88-f287-4078-8386-1f9e26f04e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ec288-c6b5-4ca8-bc21-8619fdce8e4e",
   "metadata": {},
   "source": [
    "## Define the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b504f8b7-7904-4eaf-96e1-24a1a88f1326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Student code goes here\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human. Answer only in Croatian.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813be365-f481-40ca-979c-12244ec79842",
   "metadata": {},
   "source": [
    "## Define the memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc3ce0e-4008-4e40-9bc0-a4aa7d25e0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Student code goes here\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450aae2-a64f-4d33-adb7-c4492165afe5",
   "metadata": {},
   "source": [
    "## Create the LLMChain object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b9d95c-0ec4-4898-bfb0-6453cbeb6f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Student code goes here\n",
    "conversation = LLMChain(\n",
    "    llm=dolly,\n",
    "    # LLM will be free dolly, defined above\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876812b-b3e0-46e5-b521-1fd181a5f1f2",
   "metadata": {},
   "source": [
    "## Check that it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512e422b-cfe8-4f33-bed9-beac86bcab24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human. Answer only in Croatian.\n",
      "Human: hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Pozdrav! Kako vam mogu pomoći danas?')],\n",
       " 'text': 'Pozdrav! Kako vam mogu pomoći danas?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "conversation({\"question\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396d21e-5007-4d27-a730-e06a5174a008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
